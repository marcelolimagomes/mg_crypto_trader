{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, sys.path[0].removesuffix('/src/jupyter_nb'))\n",
        "\n",
        "import pandas as pd\n",
        "from pycaret.classification import ClassificationExperiment\n",
        "import src.utils as utils\n",
        "import src.calcEMA as calc_utils\n",
        "import src.myenv as myenv\n",
        "from datetime import datetime\n",
        "\n",
        "from itertools import combinations\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Variables\n",
        "# ETCUSDT BTCUSDT\n",
        "# symbol = 'ETHUSDT'\n",
        "symbol = 'BTCUSDT'\n",
        "interval = '1m'\n",
        "# lightgbm  xgboost lr et rf\n",
        "estimator = 'knn'\n",
        "_compare_models = False\n",
        "\n",
        "start_train_date = '2022-06-01'  # train < and test >=\n",
        "start_test_date = '2023-01-01'  # train < and test >=\n",
        "\n",
        "stop_loss = 1.0\n",
        "# regression_times = 0  # 24 * 30 * 2  # horas\n",
        "times_regression_PnL = 120\n",
        "normalize = True\n",
        "use_gpu = False\n",
        "tune_model = False\n",
        "apply_combination_features = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Metadata\n",
        "\n",
        "<code>\n",
        "Field Name - Description</br>\n",
        "open_time - Kline Open time in unix time format</br>\n",
        "open - Open Price</br>\n",
        "high - High Price</br>\n",
        "low\t- Low Price</br>\n",
        "close\t- Close Price</br>\n",
        "volume - Volume</br>\n",
        "close_time - Kline Close time in unix time format</br>\n",
        "quote_volume - Quote Asset Volume</br>\n",
        "count\t- Number of Trades</br>\n",
        "taker_buy_volume - Taker buy base asset volume during this period</br>\n",
        "taker_buy_quote_volume - Taker buy quote asset volume during this period</br>\n",
        "ignore - Ignore</br>\n",
        "</code>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols = myenv.all_klines_cols.copy()\n",
        "cols.remove('ignore')\n",
        "data = utils.get_data(symbol=symbol, save_database=False, interval=interval, tail=-1, columns=cols, parse_dates=True, start_date=start_train_date)\n",
        "data = data[data['open_time'] >= start_train_date]\n",
        "data = utils.parse_type_fields(data, parse_dates=True)\n",
        "data = utils.adjust_index(data)\n",
        "data.info()\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = calc_utils.calc_RSI(data)\n",
        "data.info()\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = calc_utils.calc_ema_periods(data, periods_of_time=[times_regression_PnL, 200])\n",
        "data.info()\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = utils.regression_PnL(\n",
        "    data=data,\n",
        "    label=myenv.label,\n",
        "    diff_percent=float(stop_loss),\n",
        "    max_regression_profit_and_loss=int(times_regression_PnL),\n",
        "    drop_na=True,\n",
        "    drop_calc_cols=True,\n",
        "    strategy=None)\n",
        "data.dropna(inplace=True)\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.dropna(inplace=True)\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "perc_data_label = data[[myenv.label, 'open_time']].groupby(myenv.label).count()\n",
        "perc_data_label['perc'] = perc_data_label['open_time'] / len(data)\n",
        "perc_data_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = data[(data['open_time'] >= start_train_date) & (data['open_time'] < start_test_date)]\n",
        "train_data = train_data.sort_values(myenv.date_features)\n",
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_data = data[data['open_time'] >= start_test_date]\n",
        "test_data = test_data.sort_values(myenv.date_features)\n",
        "test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# BTCUSDT 1h best params: close,volume,quote_asset_volume,number_of_trades,rsi\n",
        "# numeric_features = 'volume,quote_asset_volume,number_of_trades,taker_buy_base_asset_volume,taker_buy_quote_asset_volume,rsi,ema_24p,ema_200p'.split(',')\n",
        "#text_numeric_features = 'close,volume,quote_asset_volume,number_of_trades,taker_buy_base_asset_volume,taker_buy_quote_asset_volume,rsi,ema_24p,ema_200p'\n",
        "text_numeric_features = f'number_of_trades,rsi,ema_{int(times_regression_PnL)}p,ema_200p'\n",
        "numeric_features = text_numeric_features.split(',')\n",
        "print(f'Numeric Features: {numeric_features} - size: {len(numeric_features)}\\n')\n",
        "\n",
        "combination_numeric_features = []\n",
        "if apply_combination_features:\n",
        "\tfor size in range(1, len(numeric_features) + 1): \n",
        "\t\tcomb = map(list, combinations(numeric_features, size))\t\n",
        "\t\tfor c in comb:\n",
        "\t\t\tres = ''\n",
        "\t\t\tfor j in c:\n",
        "\t\t\t\tres += f'{j},'\n",
        "\t\t\tcombination_numeric_features.append(res[0:len(res) - 1])\n",
        "else:\n",
        "\tcombination_numeric_features = [text_numeric_features]\n",
        "\n",
        "print(f'Combination Numeric Features: \\n{combination_numeric_features}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.utils import parallel_backend\n",
        "from datetime import datetime\n",
        "import os\n",
        "# fix_imbalance_method: condensednearestneighbour, editednearestneighborus, repeatededitednearestneighbours, allknn, instancehardnessthreshold, nearmiss, neighbourhoodcleaningrule, onesidedselection, randomundersampler, tomeklinks, randomoversampler, smote, smotenc, smoten, adasyn, borderlinesmote, kmeanssmote, svmsmote, smoteenn, smotetomek.\n",
        "# 'condensednearestneighbour,editednearestneighborus,repeatededitednearestneighbours,allknn,instancehardnessthreshold,nearmiss,neighbourhoodcleaningrule,onesidedselection,randomundersampler,tomeklinks,randomoversampler,smote,smotenc,smoten,adasyn,borderlinesmote,kmeanssmote,svmsmote,smoteenn,smotetomek'.split(',')\n",
        "# 'smotenc,smoten,adasyn,borderlinesmote,kmeanssmote,svmsmote,smoteenn,smotetomek'.split(',')\n",
        "# imbalance_list = 'editednearestneighborus,repeatededitednearestneighbours,allknn,instancehardnessthreshold,nearmiss,neighbourhoodcleaningrule,onesidedselection,randomundersampler,tomeklinks,randomoversampler,smote,smotenc,smoten,adasyn,borderlinesmote,kmeanssmote,svmsmote,smoteenn,smotetomek'.split(',')\n",
        "imbalance_list = 'instancehardnessthreshold,smoteenn,repeatededitednearestneighbours,allknn'.split(',')\n",
        "simulation_results_filename = f'./resultado_simulacao_{symbol}_{interval}.csv'\n",
        "\n",
        "df_resultado_simulacao = pd.DataFrame()\n",
        "has_simulation_file = os.path.exists(simulation_results_filename)\n",
        "if has_simulation_file:\n",
        "  df_resultado_simulacao = pd.read_csv(simulation_results_filename, sep=';')\n",
        "with parallel_backend('threading', n_jobs=20):\n",
        "  for aux_numeric_features in combination_numeric_features:\n",
        "    experiement = ClassificationExperiment()\n",
        "    features = []\n",
        "    features += ['open_time', myenv.label]\n",
        "    features += aux_numeric_features.split(',')\n",
        "    print(f'features: {features}')\n",
        "    for fix_imbalance_method in imbalance_list:\n",
        "      if has_simulation_file:\n",
        "        chave = (df_resultado_simulacao['symbol'] == symbol) & \\\n",
        "            (df_resultado_simulacao['interval'] == interval) & \\\n",
        "            (df_resultado_simulacao['estimator'] == estimator) & \\\n",
        "            (df_resultado_simulacao['fix_imbalance_method'] == fix_imbalance_method) & \\\n",
        "            (df_resultado_simulacao['features'] == str(features))\n",
        "\n",
        "        if chave.sum() > 0:\n",
        "          print(f'fix_imbalance_method: {fix_imbalance_method} already exists')\n",
        "          continue\n",
        "\n",
        "      try:\n",
        "        print(f'fix_imbalance_method: {fix_imbalance_method}')\n",
        "        setup = experiement.setup(\n",
        "            data=train_data[features].copy(),\n",
        "            train_size=myenv.train_size,\n",
        "            target=myenv.label,\n",
        "            numeric_features=aux_numeric_features.split(','),\n",
        "            date_features=['open_time'],\n",
        "            create_date_columns=[\"hour\", \"day\", \"month\"],\n",
        "            data_split_shuffle=False,\n",
        "            data_split_stratify=False,\n",
        "            fix_imbalance=True,\n",
        "            fix_imbalance_method=fix_imbalance_method,\n",
        "            remove_outliers=True,\n",
        "            fold_strategy='timeseries', \n",
        "            fold=3,\n",
        "            session_id=123,\n",
        "            normalize=normalize,\n",
        "            use_gpu=False,\n",
        "            verbose=True,\n",
        "            n_jobs=20,\n",
        "            log_experiment=False,\n",
        "        )\n",
        "\n",
        "        if _compare_models:\n",
        "          best = setup.compare_models()\n",
        "          estimator = setup.pull().index[0]\n",
        "          print('Estimator: ' + estimator)\n",
        "        else:\n",
        "          best = setup.create_model(estimator, n_jobs=20)\n",
        "\n",
        "        if tune_model:\n",
        "          best = setup.tune_model(best)\n",
        "\n",
        "        # predict on test set\n",
        "        # holdout_pred = setup.predict_model(best)\n",
        "        # print('Holdout Score:', holdout_pred['prediction_score'].mean())\n",
        "        # print('Holdout Score Group:\\n', holdout_pred[[myenv.label, 'prediction_score']].groupby(myenv.label).mean())\n",
        "\n",
        "        predict = setup.predict_model(best, data=test_data.drop(columns=[myenv.label]))\n",
        "        predict[myenv.label] = test_data[myenv.label]\n",
        "        predict['_score'] = predict['prediction_label'] == predict[myenv.label]\n",
        "        # print('Predict Score Mean:', predict['_score'].mean())\n",
        "        # print('Predict Score Mean Group:\\n', predict[[myenv.label, '_score']].groupby(myenv.label).mean())\n",
        "\n",
        "        final_model = setup.finalize_model(best)\n",
        "\n",
        "        ajusted_test_data = test_data.drop(myenv.label, axis=1)\n",
        "        df_final_predict, res_score = utils.validate_score_test_data(\n",
        "            setup,\n",
        "            final_model,\n",
        "            myenv.label,\n",
        "            test_data,\n",
        "            ajusted_test_data)\n",
        "\n",
        "        # df_final_predict.info()\n",
        "        # print('Final Score Mean:', res_score.mean().values[0])\n",
        "        # print('Final Score Group:\\n', res_score)\n",
        "\n",
        "        start_test_date = df_final_predict['open_time'].min()\n",
        "        end_test_date = df_final_predict['open_time'].max()\n",
        "\n",
        "        # print('Simule Trading:')\n",
        "        # print(f'Min Data: {start_test_date}')\n",
        "        # print(f'Max Data: {end_test_date}')\n",
        "        saldo_inicial = 100.0\n",
        "        saldo_final = utils.simule_trading_crypto2(df_final_predict, start_test_date, end_test_date, saldo_inicial, stop_loss)\n",
        "        print(f'>>>> Saldo Final: {saldo_final} - features: {features}\\n\\n')\n",
        "\n",
        "        result_simulado = {}\n",
        "        result_simulado['date'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        result_simulado['symbol'] = symbol\n",
        "        result_simulado['interval'] = interval\n",
        "        result_simulado['estimator'] = estimator\n",
        "        result_simulado['fix_imbalance_method'] = fix_imbalance_method\n",
        "        result_simulado['stop_loss'] = stop_loss\n",
        "        result_simulado['times_regression_profit_and_loss'] = times_regression_PnL\n",
        "        result_simulado['features'] = features\n",
        "        result_simulado['final_value'] = saldo_final\n",
        "\n",
        "        if res_score is not None:\n",
        "          result_simulado['score'] = ''\n",
        "          for i in range(0, len(res_score.index.values)):\n",
        "            result_simulado['score'] += f'[{res_score.index.values[i]}={res_score[\"_score\"].values[i]:.2f}]'\n",
        "\n",
        "        df_resultado_simulacao = pd.concat([df_resultado_simulacao, pd.DataFrame([result_simulado])], ignore_index=True)\n",
        "        df_resultado_simulacao.sort_values('final_value', inplace=True)\n",
        "\n",
        "        df_resultado_simulacao.to_csv(simulation_results_filename, sep=';', index=False)\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "        continue"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "conda_env3.10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
